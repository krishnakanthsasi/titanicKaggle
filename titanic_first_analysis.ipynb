{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premise \n",
    "This is the first analysis done by me on the titanic dataset.  \n",
    "I will go step by step focussing on the pointers provided to me by the vlammrs document related to this assignment.  \n",
    "The dataset used for the analysis is/or should be stored in the current folder of this script.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package pandas:\n",
      "\n",
      "NAME\n",
      "    pandas\n",
      "\n",
      "DESCRIPTION\n",
      "    pandas - a powerful data analysis and manipulation library for Python\n",
      "    =====================================================================\n",
      "    \n",
      "    **pandas** is a Python package providing fast, flexible, and expressive data\n",
      "    structures designed to make working with \"relational\" or \"labeled\" data both\n",
      "    easy and intuitive. It aims to be the fundamental high-level building block for\n",
      "    doing practical, **real world** data analysis in Python. Additionally, it has\n",
      "    the broader goal of becoming **the most powerful and flexible open source data\n",
      "    analysis / manipulation tool available in any language**. It is already well on\n",
      "    its way toward this goal.\n",
      "    \n",
      "    Main Features\n",
      "    -------------\n",
      "    Here are just a few of the things that pandas does well:\n",
      "    \n",
      "      - Easy handling of missing data in floating point as well as non-floating\n",
      "        point data.\n",
      "      - Size mutability: columns can be inserted and deleted from DataFrame and\n",
      "        higher dimensional objects\n",
      "      - Automatic and explicit data alignment: objects can be explicitly aligned\n",
      "        to a set of labels, or the user can simply ignore the labels and let\n",
      "        `Series`, `DataFrame`, etc. automatically align the data for you in\n",
      "        computations.\n",
      "      - Powerful, flexible group by functionality to perform split-apply-combine\n",
      "        operations on data sets, for both aggregating and transforming data.\n",
      "      - Make it easy to convert ragged, differently-indexed data in other Python\n",
      "        and NumPy data structures into DataFrame objects.\n",
      "      - Intelligent label-based slicing, fancy indexing, and subsetting of large\n",
      "        data sets.\n",
      "      - Intuitive merging and joining data sets.\n",
      "      - Flexible reshaping and pivoting of data sets.\n",
      "      - Hierarchical labeling of axes (possible to have multiple labels per tick).\n",
      "      - Robust IO tools for loading data from flat files (CSV and delimited),\n",
      "        Excel files, databases, and saving/loading data from the ultrafast HDF5\n",
      "        format.\n",
      "      - Time series-specific functionality: date range generation and frequency\n",
      "        conversion, moving window statistics, date shifting and lagging.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _config (package)\n",
      "    _libs (package)\n",
      "    _testing\n",
      "    _typing\n",
      "    _version\n",
      "    api (package)\n",
      "    arrays (package)\n",
      "    compat (package)\n",
      "    conftest\n",
      "    core (package)\n",
      "    errors (package)\n",
      "    io (package)\n",
      "    plotting (package)\n",
      "    testing\n",
      "    tests (package)\n",
      "    tseries (package)\n",
      "    util (package)\n",
      "\n",
      "SUBMODULES\n",
      "    _hashtable\n",
      "    _lib\n",
      "    _tslib\n",
      "    offsets\n",
      "\n",
      "FUNCTIONS\n",
      "    __getattr__(name)\n",
      "\n",
      "DATA\n",
      "    IndexSlice = <pandas.core.indexing._IndexSlice object>\n",
      "    NA = <NA>\n",
      "    NaT = NaT\n",
      "    __docformat__ = 'restructuredtext'\n",
      "    __git_version__ = '2a7d3326dee660824a8433ffd01065f8ac37f7d6'\n",
      "    describe_option = <pandas._config.config.CallableDynamicDoc object>\n",
      "    get_option = <pandas._config.config.CallableDynamicDoc object>\n",
      "    options = <pandas._config.config.DictWrapper object>\n",
      "    reset_option = <pandas._config.config.CallableDynamicDoc object>\n",
      "    set_option = <pandas._config.config.CallableDynamicDoc object>\n",
      "\n",
      "VERSION\n",
      "    1.1.2\n",
      "\n",
      "FILE\n",
      "    c:\\users\\krish\\anaconda3\\lib\\site-packages\\pandas\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BooleanDtype',\n",
       " 'Categorical',\n",
       " 'CategoricalDtype',\n",
       " 'CategoricalIndex',\n",
       " 'DataFrame',\n",
       " 'DateOffset',\n",
       " 'DatetimeIndex',\n",
       " 'DatetimeTZDtype',\n",
       " 'ExcelFile',\n",
       " 'ExcelWriter',\n",
       " 'Float64Index',\n",
       " 'Grouper',\n",
       " 'HDFStore',\n",
       " 'Index',\n",
       " 'IndexSlice',\n",
       " 'Int16Dtype',\n",
       " 'Int32Dtype',\n",
       " 'Int64Dtype',\n",
       " 'Int64Index',\n",
       " 'Int8Dtype',\n",
       " 'Interval',\n",
       " 'IntervalDtype',\n",
       " 'IntervalIndex',\n",
       " 'MultiIndex',\n",
       " 'NA',\n",
       " 'NaT',\n",
       " 'NamedAgg',\n",
       " 'Period',\n",
       " 'PeriodDtype',\n",
       " 'PeriodIndex',\n",
       " 'RangeIndex',\n",
       " 'Series',\n",
       " 'SparseDtype',\n",
       " 'StringDtype',\n",
       " 'Timedelta',\n",
       " 'TimedeltaIndex',\n",
       " 'Timestamp',\n",
       " 'UInt16Dtype',\n",
       " 'UInt32Dtype',\n",
       " 'UInt64Dtype',\n",
       " 'UInt64Index',\n",
       " 'UInt8Dtype',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__docformat__',\n",
       " '__file__',\n",
       " '__getattr__',\n",
       " '__git_version__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " '_config',\n",
       " '_hashtable',\n",
       " '_is_numpy_dev',\n",
       " '_lib',\n",
       " '_libs',\n",
       " '_np_version_under1p16',\n",
       " '_np_version_under1p17',\n",
       " '_np_version_under1p18',\n",
       " '_testing',\n",
       " '_tslib',\n",
       " '_typing',\n",
       " '_version',\n",
       " 'api',\n",
       " 'array',\n",
       " 'arrays',\n",
       " 'bdate_range',\n",
       " 'compat',\n",
       " 'concat',\n",
       " 'core',\n",
       " 'crosstab',\n",
       " 'cut',\n",
       " 'date_range',\n",
       " 'describe_option',\n",
       " 'errors',\n",
       " 'eval',\n",
       " 'factorize',\n",
       " 'get_dummies',\n",
       " 'get_option',\n",
       " 'infer_freq',\n",
       " 'interval_range',\n",
       " 'io',\n",
       " 'isna',\n",
       " 'isnull',\n",
       " 'json_normalize',\n",
       " 'lreshape',\n",
       " 'melt',\n",
       " 'merge',\n",
       " 'merge_asof',\n",
       " 'merge_ordered',\n",
       " 'notna',\n",
       " 'notnull',\n",
       " 'offsets',\n",
       " 'option_context',\n",
       " 'options',\n",
       " 'pandas',\n",
       " 'period_range',\n",
       " 'pivot',\n",
       " 'pivot_table',\n",
       " 'plotting',\n",
       " 'qcut',\n",
       " 'read_clipboard',\n",
       " 'read_csv',\n",
       " 'read_excel',\n",
       " 'read_feather',\n",
       " 'read_fwf',\n",
       " 'read_gbq',\n",
       " 'read_hdf',\n",
       " 'read_html',\n",
       " 'read_json',\n",
       " 'read_orc',\n",
       " 'read_parquet',\n",
       " 'read_pickle',\n",
       " 'read_sas',\n",
       " 'read_spss',\n",
       " 'read_sql',\n",
       " 'read_sql_query',\n",
       " 'read_sql_table',\n",
       " 'read_stata',\n",
       " 'read_table',\n",
       " 'reset_option',\n",
       " 'set_eng_float_format',\n",
       " 'set_option',\n",
       " 'show_versions',\n",
       " 'test',\n",
       " 'testing',\n",
       " 'timedelta_range',\n",
       " 'to_datetime',\n",
       " 'to_numeric',\n",
       " 'to_pickle',\n",
       " 'to_timedelta',\n",
       " 'tseries',\n",
       " 'unique',\n",
       " 'util',\n",
       " 'value_counts',\n",
       " 'wide_to_long']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_excel(r'Titanic_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived2</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cherbourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>712833</td>\n",
       "      <td>C85</td>\n",
       "      <td>Queenstown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cherbourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>113803</td>\n",
       "      <td>531</td>\n",
       "      <td>C123</td>\n",
       "      <td>Cherbourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cherbourg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId Survived2  Pclass  \\\n",
       "0            1       Yes       3   \n",
       "1            2         0       1   \n",
       "2            3         0       3   \n",
       "3            4         0       1   \n",
       "4            5       Yes       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "             Ticket    Fare Cabin    Embarked  \n",
       "0         A/5 21171     725   NaN   Cherbourg  \n",
       "1          PC 17599  712833   C85  Queenstown  \n",
       "2  STON/O2. 3101282    7925   NaN   Cherbourg  \n",
       "3            113803     531  C123   Cherbourg  \n",
       "4            373450     805   NaN   Cherbourg  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 11 columns and data points for 891 passengers. Were these all the passengers on the ship?\n",
    "***A quick google search shows that 2208 people were onboard, including crew members***  \n",
    "***1317 passengers 324 in first class, 284 in second class, and 709 in third class*** - source:wiki  \n",
    "**Of which 1503, or 1512 people died**  \n",
    "How come we have only data for these members?  \n",
    "Seems to be that, this is only a test set. Additionally, it is also known that certain orgiinal available has more columns present.  \n",
    "\n",
    "The question is more on how this dataset was generated?  \n",
    "\n",
    "Even though there seems to be variety of information, I am not entirely sure which direction to go towards. Should I investigate, what were the causes of the sinkage? Should I investigate what could have been predicted? And what could be avoided, and planned well from now on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>8.910000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>38.420168</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>1.276607e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>56.525211</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>4.111230e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.610000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.625000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.895800e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>705.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.123292e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId      Pclass         Age       SibSp          Fare\n",
       "count   891.000000  891.000000  714.000000  891.000000  8.910000e+02\n",
       "mean    446.000000    2.308642   38.420168    0.523008  1.276607e+05\n",
       "std     257.353842    0.836071   56.525211    1.102743  4.111230e+05\n",
       "min       1.000000    1.000000    1.000000    0.000000  0.000000e+00\n",
       "25%     223.500000    2.000000   21.000000    0.000000  1.610000e+02\n",
       "50%     446.000000    3.000000   29.000000    0.000000  2.625000e+03\n",
       "75%     668.500000    3.000000   40.000000    1.000000  7.895800e+04\n",
       "max     891.000000    3.000000  705.000000    8.000000  5.123292e+06"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived2    891 non-null    object \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Ticket       891 non-null    object \n",
      " 8   Fare         891 non-null    int64  \n",
      " 9   Cabin        204 non-null    object \n",
      " 10  Embarked     891 non-null    object \n",
      "dtypes: float64(1), int64(4), object(6)\n",
      "memory usage: 76.7+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Possible connections - 45**   \n",
    "1. Class - Fare, Cabin.\n",
    ">Were people in higher classes paying more than the rest? Should be obvious.\n",
    "2. Survied to (calss, sex, age, sibsp, Cabin, embarked)\n",
    ">wealthy people priotised over poorer people. also reads as social class. there higher classes would be given higher priority.  \n",
    ">Maybe one of the genders is given higher preference.\n",
    ">Maybe kids and elderly, or a particular age group is given precedence.\n",
    ">Did kids with more or less siblings survive better than others?\n",
    ">Cabin : Did location play an influence in the surivival chance of the passengers?\n",
    ">Were people boarding from certain regions more likely to survive than the rest?\n",
    ">Does the ticket, and fare play any role in the chances of survival?\n",
    ">How much influence does each of the attributes play a role in the survival rate of the passengers? \n",
    "3. What is the gender distribution in each of the classes?\n",
    "4. More trivial information such as Name and class?\n",
    ">Certain surnames more prominent in upper classes?\n",
    "5. Was there a relationship between SibSp and class?\n",
    ">Such as wealthier or higher class having more kids? or even the other way round.\n",
    "6. Was there a relationship between Sex and class?\n",
    "7. And maybe even between class and embarked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additional curiosities**\n",
    "1. Was the cabin number missing for a particular class of passengers?\n",
    "2. Ensuring to remove the bias occuring from Sibsp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quality of Data**\n",
    "1. Some of the column headers are not very clear, but can be guessed on what they intend.\n",
    ">survived2 should be survived.  \n",
    ">Pclass should be passenger class  \n",
    ">SibSp should be siblings of the passenger. This part was the most difficult part, but can be shown by looking the surnames, age, and SibSp count.   \n",
    "2. Cabin has a lot of missing values. It only has 204 non-null values.\n",
    "3. There are also missing values in age column, however it is only for 704 for the total count.\n",
    ">What ought to be done with the missing values? In case where there is a lot of missing values, it would be most practical drop that particular column. \n",
    ">However what should be approach for Age column,? Should I drop it as well, or all the rows for each the value doesn't exist? Or should I fill it with 0, or mean, or using the age distribution. The last one seems to be most solid, mathematically. Since statistical methods are aggregatory, it ought to be fine with the distribution as long as the distribution is maintained. Can I prove it mathematically?  \n",
    "4. Presence of outliers/anomalies, A quick glimplse earlier showed possibility of anomalies in the data apart from the missing values. Is this true, and can these anomalies be explained, or are they errors during the data creation. What should be done with them incase found.? How to find them?  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_cabinless = titanic.drop(labels='Cabin', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived2    891 non-null    object \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Ticket       891 non-null    object \n",
      " 8   Fare         891 non-null    int64  \n",
      " 9   Embarked     891 non-null    object \n",
      "dtypes: float64(1), int64(4), object(5)\n",
      "memory usage: 69.7+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_cabinless.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    136\n",
      "1     30\n",
      "2     11\n",
      "Name: Pclass, dtype: int64\n",
      "Yes    125\n",
      "0       52\n",
      "Name: Survived2, dtype: int64\n",
      "male      124\n",
      "female     53\n",
      "Name: Sex, dtype: int64\n",
      "0    137\n",
      "1     26\n",
      "8      7\n",
      "3      4\n",
      "2      3\n",
      "Name: SibSp, dtype: int64\n",
      "775      20\n",
      "78958    15\n",
      "805      14\n",
      "0         8\n",
      "6955      7\n",
      "         ..\n",
      "355       1\n",
      "86625     1\n",
      "50        1\n",
      "95        1\n",
      "87125     1\n",
      "Name: Fare, Length: 73, dtype: int64\n",
      "Cherbourg       90\n",
      "Southhampton    49\n",
      "Queenstown      38\n",
      "Name: Embarked, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(titanic_cabinless[titanic_cabinless.Age.isnull()].Pclass.value_counts())\n",
    "print(titanic_cabinless[titanic_cabinless.Age.isnull()].Survived2.value_counts())\n",
    "print(titanic_cabinless[titanic_cabinless.Age.isnull()].Sex.value_counts())\n",
    "print(titanic_cabinless[titanic_cabinless.Age.isnull()].SibSp.value_counts())\n",
    "print(titanic_cabinless[titanic_cabinless.Age.isnull()].Fare.value_counts())\n",
    "print(titanic_cabinless[titanic_cabinless.Age.isnull()].Embarked.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    547\n",
       "2     94\n",
       "3     21\n",
       "4     11\n",
       "7      3\n",
       "6      3\n",
       "5      2\n",
       "Name: Ticket, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_cabinless.Ticket.value_counts().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74       Bing, Mr. Lee\n",
      "169      Ling, Mr. Lee\n",
      "509     Lang, Mr. Fang\n",
      "643    Foo, Mr. Choong\n",
      "692       Lam, Mr. Ali\n",
      "826       Lam, Mr. Len\n",
      "838    Chip, Mr. Chang\n",
      "Name: Name, dtype: object\n",
      "13                           Andersson, Mr. Anders Johan\n",
      "119                    Andersson, Miss. Ellis Anna Maria\n",
      "541                 Andersson, Miss. Ingeborg Constanzia\n",
      "542                    Andersson, Miss. Sigrid Elisabeth\n",
      "610    Andersson, Mrs. Anders Johan (Alfrida Konstant...\n",
      "813                   Andersson, Miss. Ebba Iris Alfrida\n",
      "850              Andersson, Master. Sigvard Harald Elias\n",
      "Name: Name, dtype: object\n",
      "159           Sage, Master. Thomas Henry\n",
      "180         Sage, Miss. Constance Gladys\n",
      "201                  Sage, Mr. Frederick\n",
      "324             Sage, Mr. George John Jr\n",
      "792              Sage, Miss. Stella Anna\n",
      "846             Sage, Mr. Douglas Bullen\n",
      "863    Sage, Miss. Dorothy Edith \"Dolly\"\n",
      "Name: Name, dtype: object\n",
      "59          Goodwin, Master. William Frederick\n",
      "71                  Goodwin, Miss. Lillian Amy\n",
      "386            Goodwin, Master. Sidney Leonard\n",
      "480             Goodwin, Master. Harold Victor\n",
      "678    Goodwin, Mrs. Frederick (Augusta Tyler)\n",
      "683                Goodwin, Mr. Charles Edward\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(titanic_cabinless.loc[titanic_cabinless['Ticket']=='1601'].Name)\n",
    "print(titanic_cabinless.loc[titanic_cabinless['Ticket']=='347082'].Name)\n",
    "print(titanic_cabinless.loc[titanic_cabinless['Ticket']=='CA. 2343'].Name)\n",
    "print(titanic_cabinless.loc[titanic_cabinless['Ticket']=='CA 2144'].Name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding each column well, and writing a short description of each\n",
    "Example\n",
    "1. Ticket column:\n",
    "Groups of people who are travelling together are assigned a single ticket.\n",
    "*Ingenuine ideas: Since groups are assigned by a single ticket, I can find out how survivability affected each group. Did every family lose someone in the mix? What was the distribution of group sizes in each class?*\n",
    ">Did it also happen than people who were from the same family also assigned a different tickets? So groups travelling together, but each passenger within the group was assigned a unique ticket.? How do I check this?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointers expected in the solution\n",
    "\n",
    "1. What connections can you find in these data?  \n",
    "There are 11 columns, with col1 being the primary key marking each passenger with a userid.\n",
    "Rest of the columns are survived, class, name, sex, age, *sibsp* is not a clear label for the column, ticket is the identifier for tickets bought, fare doesn't denote the currency, cabin describes the cabin label or number of the passengers, embarked is the source of the journey for the passenger.\n",
    "\n",
    "Steps to understanding the dataset better.\n",
    "1. Are there columns which do not add new information? Can they be dropped from our analysis?\n",
    "2. Are there missing values in the each of the columns?\n",
    "3. Are there outliers or anomalies in the presented data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. When you place the data in the present time, for whom is this knowledge interesting?\n",
    "3. What would your advice be if you were instructed to analyze this data for an insurance company?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
